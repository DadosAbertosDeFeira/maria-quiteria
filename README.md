# Maria Quit√©ria

![CI](https://github.com/DadosAbertosDeFeira/maria-quiteria/workflows/CI/badge.svg)

Um projeto para libertar dados do munic√≠pio de [Feira de Santana](https://pt.wikipedia.org/wiki/Feira_de_Santana).

N√£o sabe quem foi [Maria Quit√©ria](https://pt.wikipedia.org/wiki/Maria_Quit%C3%A9ria)?

## Dados

| Base de dados | Fonte | Descri√ß√£o        | Coleta          | Banco de dados | Download |
| ------------- | ------------- | ------------- |:-------------:|:-----:|:-----:|
| Agenda (`citycouncil.py`) | C√¢mara Municipal | Agenda (ordem do dia, homenagens, sess√µes ordin√°rias etc) da C√¢mara Municipal. | :heavy_check_mark: | :heavy_check_mark: | üîú |
| Atas das sess√µes (`citycouncil.py`) | C√¢mara Municipal | Atas das sess√µes da C√¢mara Municipal. | :heavy_check_mark: | :heavy_check_mark: | üîú |
| Lista de Presen√ßa (`citycouncil.py`) | C√¢mara Municipal | Assiduidade dos vereadores da C√¢mara Municipal. | :heavy_check_mark: | :heavy_check_mark: | üîú |
| Despesas (`citycouncil.py`) | C√¢mara Municipal | Gastos realizados pela C√¢mara Municipal. | :heavy_check_mark: | :heavy_check_mark: | [Kaggle](https://www.kaggle.com/anapaulagomes/despesas-da-cmara-municipal) |
| Contratos (`cityhall.py`) | Prefeitura | Contratos realizados pela prefeitura entre 2016 e 2017. | :heavy_check_mark: | üîú | [Kaggle](https://www.kaggle.com/anapaulagomes/contratos-da-prefeitura-de-feira-de-santana) |
| Di√°rio Oficial (`gazette.py`) | Prefeitura/C√¢mara de Vereadores | Di√°rio oficial do executivo e legislativo desde 2015. | :heavy_check_mark: | :heavy_check_mark: | [Kaggle](https://www.kaggle.com/anapaulagomes/dirios-oficiais-de-feira-de-santana)  |
| Di√°rio Oficial (legado - antes de 2015) (`gazette.py`) | Prefeitura | Leis e decretos entre 1999 e 2015. | :heavy_check_mark: | :heavy_check_mark: | [Kaggle](https://www.kaggle.com/anapaulagomes/dirios-oficiais-de-feira-de-santana-at-2015) |
| Licita√ß√µes (`cityhall.py`) | Prefeitura | Licita√ß√µes realizadas pela prefeitura desde 2015. | :heavy_check_mark: | üîú | [Kaggle](https://www.kaggle.com/anapaulagomes/licitaes-da-prefeitura-de-feira-de-santana) |
| Pagamentos (`cityhall.py`) | Prefeitura | Pagamentos realizados pela prefeitura desde 2010. | :heavy_check_mark: | üîú | [Kaggle](https://www.kaggle.com/anapaulagomes/pagamentos-da-prefeitura-de-feira-de-santana) |

## Contribuindo para o projeto

Contribui√ß√µes s√£o muito bem-vindas. Veja como contribuir no nosso [Guia de Contribui√ß√£o](CONTRIBUTING.md).

Toda a comunica√ß√£o e demais intera√ß√µes do Dados Abertos de Feira est√£o sujeitas
ao nosso [C√≥digo de Conduta](CODE_OF_CONDUCT.md).

## Coleta

Esse projeto usa [Scrapy](https://docs.scrapy.org/en/latest/) para a coleta de dados
e [Django](https://www.djangoproject.com/) para o _backend_.

### Configurando seu ambiente

* Instale as depend√™ncias

Para rodar esse projeto localmente, instale as depend√™ncias:

```bash
pip install -r dev_requirements.txt
```

* Carregue as vari√°veis de ambiente

Um exemplo das configura√ß√µes pode ser encontrado no arquivo `.env.example`
(que pode ser copiado para um arquivo `.env` na raiz do projeto).

* Postgres

Esse projeto usa o Postgres. Para rodar o banco de dados local, crie um
banco de dados com o nome `mariaquiteria`.

Adicione a vari√°vel de ambiente `DATABASE_URL` com a url de conex√£o ao seu Postgres.
Ex: `DATABASE_URL=postgres://USER:PASSWORD@HOST:PORT/NAME`

Depois basta aplicar as `migrations`:

```
python manage.py migrate
```

#### Usando Docker

Se voc√™ n√£o quiser instalar todas as depend√™ncias, voc√™ pode instalar o [Docker](https://docs.docker.com/install/) em conjunto com o [Docker Compose](https://docs.docker.com/compose/install/).

Para isso, voc√™ precisa criar um `.env` como no `.env.example` da raiz do projeto.

* Executando o projeto no Docker:

1. Iniciando o servi√ßo:

```
make build
```

2. Crie as tabelas no banco:

```
make migrate
```

3. Crie um usuario `admin`:

```
make createsuperuser
```

4. Processe e move arquivos est√°ticos:

```
make collectstatic
```

5. Executando o servi√ßo:

```
make setup
```

6. Rodando os testes:

```
make test
```

Nas pr√≥ximas vezes, basta executar os containers: `docker-compose up` e acesse [localhost:8000/admin](http://localhost:8000/admin)


Para a acessar o banco depois com seu cliente preferido, basta usar os seguintes dados:

```
User: postgres
Password: postgres
Database: mariaquiteria
Host: localhost
```

#### Executando os testes

```
make runtests
```

* Admin

Para navegar na admin, primeiro crie um super administrador:
```
python manage.py createsuperuser
```

Depois, rode o servidor com:
```
python manage.py runserver
```

Com as configura√ß√µes padr√£o o painel de controle estar√° acess√≠vel pela URL: [`127.0.0.1`](http://127.0.0.1:8000).

* Java

Nesse projeto utilizamos o [Apache Tika](https://tika.apache.org/download.html)
para extrair o conte√∫do dos arquivos de licita√ß√µes, contratos e outros.
Para t√™-lo funcionando com esse projeto voc√™ precisa apenas do Java +7
instalado na sua m√°quina (pode ser a JRE mesmo).

### Rodando os spiders

No diret√≥rio `scraper` voc√™ poder√° encontrar os _spiders_ respons√°veis pela
coleta dos dados. Para entender melhor como eles funcionam, d√™ uma olhada
na documenta√ß√£o do [scrapy](https://docs.scrapy.org/).

Para executar um _spider_, execute:

```
scrapy crawl cityhall_payments
scrapy crawl cityhall_payments -a start_from_date=03/01/2020
```

Para salvar os dados de um _spider_ em um arquivo:

```
scrapy crawl cityhall_payments -o pagamentos.json
```

Voc√™ pode substituir `json` por outros formatos como `csv`.

#### Extraindo o conte√∫do dos arquivos ao rodar os spiders

Para incluir o conte√∫do dos arquivos nos itens raspados
voc√™ deve configurar a vari√°vel de ambiente `EXTRACT_FILE_CONTENT_FROM_PIPELINE`
como `True`.

### Salvando dados da coleta no banco de dados

Para executar os _spiders_ e salvar os itens no banco de dados, execute:

```
python manage.py crawl
```

Caso queira passar alguma configura√ß√£o extra para o Scrapy atrav√©s
do comando `crawl` voc√™ pode adicionar ap√≥s o par√¢metro `--scrapy-args`:

```
./manage.py crawl --scrapy-args '{"LOG_FILE": "test.log"}'
```

#### Servi√ßo de fila e processamento ass√≠ncrono

Voc√™ pode utilizar ou n√£o um servi√ßo de fila para processamento ass√≠ncrono. Isso
√© **totalmente** opcional. Essa funcionalidade pode ser utilizada para
extra√≠rmos o conte√∫do de PDFs para texto, com o Tika, de maneira ass√≠ncrona √†
raspagem de dados. Por padr√£o, essa funcionalidade est√° ativada, seguindo
a configura√ß√£o do ambiente de produ√ß√£o.

Para utiliz√°-la, basta instalar o RabbitMQ. Para essa √∫ltima parte, temos duas
formas de te ajudar. Basta seguir para a pr√≥xima se√ß√£o.

Caso queira desativar essa funcionalidade, voc√™ vai precisar configurar a vari√°vel
de ambiente `ASYNC_FILE_PROCESSING` para `False`.

##### Utilizando o Docker para subir o RabbitMQ

Se voc√™ n√£o quiser instalar o RabbitMQ, a forma mais pr√°tica de ter uma
inst√¢ncia dele rodando √© com o [Docker](https://docs.docker.com/install/):

```
docker run -p 5672:5672 rabbitmq
```

Deixe esse processo rodando em uma janela do terminal.
Em outra janela, execute o `dramatiq`:

```
dramatiq datasets.tasks -p3 -v
```

##### Instalando o RabbitMQ localmente

Caso prefira, voc√™ pode
[baixar e instalar](https://www.rabbitmq.com/download.html) o RabbitMQ do site
oficial. Feito isso, inicie o servi√ßo em uma janela do terminal e mantenha essa
janela aberta:

```
rabbitmq-server
```
